<launch>
    <arg name="width" default="1280"/>
    <arg name="height" default="720"/>

    <!-- FROM v4l_imx390_raw.launch -->

    <!-- You can check the device ID and subdev ID for the IMX390 camera attached
    by running /opt/edge_ai_apps/scripts/setup_cameras.sh.
    Accordingly please update the parameters pass as arguments -->
    <arg name="device" default="/dev/video18"/>
    <arg name="subdev" default="/dev/v4l-subdev7"/>
    <!-- framerate (integer): inactive, 30 FPS (default, max) -->
    <!-- Can be enabled by e.g., adding videorate before tiovxdlcolorconvert, but it creases A72 loading -->
    <arg name="framerate" default="30"/>
    <!-- node name -->
    <arg name="node_name" default="gscam_node"/>
    <!-- camera name: also used as namespace for the output topic name -->
    <arg name="camera_name" default="imx390"/>
    <!-- DCC VISS binary file -->
    <arg name="dcc_isp_file" default="/opt/imaging/imx390/dcc_viss.bin"/>
    <!-- DCC 2A binary file -->
    <arg name="dcc_2a_file" default="/opt/imaging/imx390/dcc_2a.bin"/>
    <!-- LDC binary file -->
    <arg name="ldc_dcc_prefix" default="/opt/imaging/imx390/imx390_35244_equidistant_"/>
    <!-- camera_info URL: replace with camera_info from camera calibration -->
    <!-- <arg name="camera_info_url" default="package://gscam/config/IMX390_HD_camera_info.yaml"/> -->
    <!-- <arg name="camera_info_url" default="file:///opt/imaging/imx390/imx390_35244_fisheye.yml"/> -->
    <arg name="camera_info_url" default="file:///opt/imaging/imx390/imx390_35244_equidistant_1280x720_rect.yml"/>

    <!-- GStreamer pipeline specified in gscam_config was tested with IMX390 camera,
        'edgeai-tiovx-modules' and 'edgeai-gst-plugins' are assumed to be already installed in TDA4 ROS container.
        Raw resolution is 1936 x 1096 at 30 FPS.
        Note: /dev/v4l-subdev ID can change, depending on the device attached, and at reboot. -->
    <node pkg="gscam" name="$(arg node_name)" type="gscam" output="screen">
        <param name="gscam_config"
            value="v4l2src device=$(arg device) do-timestamp=true ! video/x-bayer, width=1936, height=1096, format=rggb12 !
            tiovxisp sink_0::device=$(arg subdev) sensor-name=SENSOR_SONY_IMX390_UB953_D3 dcc-isp-file=$(arg dcc_isp_file)
            sink_0::dcc-2a-file=$(arg dcc_2a_file) format-msb=11 ! video/x-raw, format=NV12 !
            tiovxldc sensor-name=SENSOR_SONY_IMX390_UB953_D3 lut-file=$(arg ldc_dcc_prefix)$(arg width)x$(arg height)_LUT.bin ldc-ds-factor=2 ldc-table-width=$(arg width) ldc-table-height=$(arg height) !
            video/x-raw, format=NV12, width=$(arg width), height=$(arg height) !
            tiovxdlcolorconvert target=1 out-pool-size=4 "/>
        <param name="camera_name"     value="$(arg camera_name)"/>
        <param name="camera_info_url" value="$(arg camera_info_url)"/>
        <param name="width"           value="$(arg width)"/>
        <param name="height"          value="$(arg height)"/>
        <param name="framerate"       value="$(arg framerate)"/>
        <param name="sync_sink"       value="false"/>
        <param name="use_gst_timestamps" value="false"/>
        <!-- image encoding: "yuv420" - publish in NV12 -->
        <param name="image_encoding"  value="yuv420"/>
    </node>


    <!-- Object Detection CNN (ti_vision_cnn) -->
    <!-- FROM gscam_objdet_cnn.launch -->
    <arg name="dl_model_path" default="/opt/model_zoo/ONR-OD-8080-yolov3-lite-regNetX-1.6gf-bgr-mmdet-coco-512x512"/>
    <arg name="exportPerfStats" default="0"/>
    <node pkg = "ti_vision_cnn" type = "vision_cnn" name = "vision_cnn" output = "screen" args = "" required = "true">
        <rosparam file="$(find ti_vision_cnn)/config/params.yaml" subst_value="true" />
        <param name = "width" value = "$(arg width)"/>
        <param name = "height" value = "$(arg height)"/>
        <!-- Input image format: 0 - VX_DF_IMAGE_U8, 1 - VX_DF_IMAGE_NV12, 2 - VX_DF_IMAGE_UYVY | 0, 1, 2 -->
        <param name = "image_format" value = "1"/>
        <param name = "enable_ldc_node" value= "0"/>
        <!-- <param name = "lut_file_path" value = "$(arg ldc_dcc_file)"/> -->
        <param name = "lut_file_path" value = ""/>
        <param name = "dl_model_path" value = "$(arg dl_model_path)"/>
        <!-- image_raw is already undistorted, just use it here -->
        <param name = "input_topic_name" value = "$(arg camera_name)/image_raw"/>
        <!-- This is a hack to handle the fact LDC happens outside this node now -->
        <!-- TODO - modify this node to disable publishing to rectified_image_topic to save bandwidth -->
        <param name = "rectified_image_topic" value = "$(arg camera_name)/ignore/image_rect_nv12"/>
        <param name = "rectified_image_frame_id" value = "$(arg camera_name)"/>
        <param name = "vision_cnn_tensor_topic" value = "$(arg camera_name)/vision_cnn/tensor"/>
        <param name = "exportPerfStats" value = "$(arg exportPerfStats)"/>
    </node>


    <!-- AOP_3d_Tracking.launch -->
    <!-- FOR TESTING, DON'T LAUNCH THE RADAR HERE BECAUSE YOU NEED TO RESET ITS POWER EVERY TIME YOU STREAM -->
    <!--<include ns="radar_1" file="$(find ti_mmwave_rospkg)/launch/AOP_3d_Tracking.launch" /> -->
    <!-- d3_fusion launch file removes rviz and sets the serial ports appropriately -->
    <include ns="radar_1" file="$(find d3_fusion)/launch/AOP_3d_Tracking.launch" /> 


    <!-- Run this on the host side docker container for visualization
    <node pkg="d3_fusion" type="fusion_cnn_radar.py" name="radar_camera_fusion_node" ns="fusion1" output="screen">
        <param name="camera_name" value="imx390"/>
        <remap from="/image_raw" to="/imx390/image_raw_rgb"/>
    </node>
    -->


</launch>
